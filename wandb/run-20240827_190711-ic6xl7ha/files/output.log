INTERSESSION: csl
LOADING EMG TENSOR...
0it [00:00, ?it/s]
 SUBJECT #1
TEST SESSION #2, TRAIN SESSION #1
ADAPT REP #10
  0%|                                                                                        | 0/2 [00:00<?, ?it/s]
  0%|                                                                                        | 0/2 [00:00<?, ?it/s]
Learning Rate: [5e-05]
Epoch 1 / 15, step 20 / 393, loss = 3345.145020
Epoch 1 / 15, step 40 / 393, loss = 3329.575195
Epoch 1 / 15, step 60 / 393, loss = 3303.035400
Epoch 1 / 15, step 80 / 393, loss = 3304.541016
Epoch 1 / 15, step 100 / 393, loss = 3268.168457
Epoch 1 / 15, step 120 / 393, loss = 3229.141357
Epoch 1 / 15, step 140 / 393, loss = 3211.312012
Epoch 1 / 15, step 160 / 393, loss = 3185.687500
Epoch 1 / 15, step 180 / 393, loss = 3118.543457
Epoch 1 / 15, step 200 / 393, loss = 3091.547363
Epoch 1 / 15, step 220 / 393, loss = 3086.373291
Epoch 1 / 15, step 240 / 393, loss = 3016.243652
Epoch 1 / 15, step 260 / 393, loss = 2986.322510
Epoch 1 / 15, step 280 / 393, loss = 2966.286377
Epoch 1 / 15, step 300 / 393, loss = 2898.255371
Epoch 1 / 15, step 320 / 393, loss = 2897.635986
Epoch 1 / 15, step 340 / 393, loss = 2874.267578
Epoch 1 / 15, step 360 / 393, loss = 2771.064941
Epoch 1 / 15, step 380 / 393, loss = 2701.493896
TOTAL TIME ELAPSED: 0.0h, 0.052081127961476646min
Learning Rate: [4.9999999999999935e-05]
Epoch 2 / 15, step 20 / 393, loss = 2683.513428
Epoch 2 / 15, step 40 / 393, loss = 2617.029785
Epoch 2 / 15, step 60 / 393, loss = 2613.791504
Epoch 2 / 15, step 80 / 393, loss = 2538.785889
Epoch 2 / 15, step 100 / 393, loss = 2474.167725
Epoch 2 / 15, step 120 / 393, loss = 2441.570312
Epoch 2 / 15, step 140 / 393, loss = 2371.080566
Epoch 2 / 15, step 160 / 393, loss = 2402.288574
Epoch 2 / 15, step 180 / 393, loss = 2443.663574
Epoch 2 / 15, step 200 / 393, loss = 2355.172852
Epoch 2 / 15, step 220 / 393, loss = 2293.332520
Epoch 2 / 15, step 240 / 393, loss = 2267.648926
Epoch 2 / 15, step 260 / 393, loss = 2265.336914
Epoch 2 / 15, step 280 / 393, loss = 2177.161621
Epoch 2 / 15, step 300 / 393, loss = 2153.687988
Epoch 2 / 15, step 320 / 393, loss = 2152.949219
Epoch 2 / 15, step 340 / 393, loss = 2065.918701
Epoch 2 / 15, step 360 / 393, loss = 2117.709717
Epoch 2 / 15, step 380 / 393, loss = 2113.913330
TOTAL TIME ELAPSED: 0.0h, 0.10162670214970906min
Learning Rate: [4.9999999999999935e-05]
Epoch 3 / 15, step 20 / 393, loss = 2035.647339
Epoch 3 / 15, step 40 / 393, loss = 2018.072998
Epoch 3 / 15, step 60 / 393, loss = 1965.193359
Epoch 3 / 15, step 80 / 393, loss = 1969.161377
Epoch 3 / 15, step 100 / 393, loss = 1936.345337
Epoch 3 / 15, step 120 / 393, loss = 1916.815918
Epoch 3 / 15, step 140 / 393, loss = 1986.337524
Epoch 3 / 15, step 160 / 393, loss = 1926.961304
Epoch 3 / 15, step 180 / 393, loss = 1845.460083
Epoch 3 / 15, step 200 / 393, loss = 1763.850952
Epoch 3 / 15, step 220 / 393, loss = 1736.735840
Epoch 3 / 15, step 240 / 393, loss = 1819.543335
Epoch 3 / 15, step 260 / 393, loss = 1796.294189
Epoch 3 / 15, step 280 / 393, loss = 1744.386230
Epoch 3 / 15, step 300 / 393, loss = 1780.766846
Epoch 3 / 15, step 320 / 393, loss = 1806.682617
Epoch 3 / 15, step 340 / 393, loss = 1739.765625
Epoch 3 / 15, step 360 / 393, loss = 1684.057007
Epoch 3 / 15, step 380 / 393, loss = 1825.484985
TOTAL TIME ELAPSED: 0.0h, 0.1517008900642395min
Learning Rate: [4.9999999999999935e-05]
Epoch 4 / 15, step 20 / 393, loss = 1700.856445
Epoch 4 / 15, step 40 / 393, loss = 1648.835205
Epoch 4 / 15, step 60 / 393, loss = 1659.885376
Epoch 4 / 15, step 80 / 393, loss = 1623.239014
Epoch 4 / 15, step 100 / 393, loss = 1633.802979
Epoch 4 / 15, step 120 / 393, loss = 1611.876221
Epoch 4 / 15, step 140 / 393, loss = 1649.536865
Epoch 4 / 15, step 160 / 393, loss = 1621.818237
Epoch 4 / 15, step 180 / 393, loss = 1658.316406
Epoch 4 / 15, step 200 / 393, loss = 1546.993652
Epoch 4 / 15, step 220 / 393, loss = 1675.817505
Epoch 4 / 15, step 240 / 393, loss = 1564.579712
Epoch 4 / 15, step 260 / 393, loss = 1544.788696
Epoch 4 / 15, step 280 / 393, loss = 1586.448730
Epoch 4 / 15, step 300 / 393, loss = 1554.451294
Epoch 4 / 15, step 320 / 393, loss = 1584.097656
Epoch 4 / 15, step 340 / 393, loss = 1528.298584
Epoch 4 / 15, step 360 / 393, loss = 1563.072144
Epoch 4 / 15, step 380 / 393, loss = 1547.826294
TOTAL TIME ELAPSED: 0.0h, 0.2034505248069763min
Learning Rate: [4.9999999999999935e-05]
Epoch 5 / 15, step 20 / 393, loss = 1509.833374
Epoch 5 / 15, step 40 / 393, loss = 1476.458496
Epoch 5 / 15, step 60 / 393, loss = 1501.325562
Epoch 5 / 15, step 80 / 393, loss = 1491.849243
Epoch 5 / 15, step 100 / 393, loss = 1497.990723
Epoch 5 / 15, step 120 / 393, loss = 1415.511108
Epoch 5 / 15, step 140 / 393, loss = 1458.923096
Epoch 5 / 15, step 160 / 393, loss = 1468.393677
Epoch 5 / 15, step 180 / 393, loss = 1468.612183
Epoch 5 / 15, step 200 / 393, loss = 1478.855469
Epoch 5 / 15, step 220 / 393, loss = 1367.514648
Epoch 5 / 15, step 240 / 393, loss = 1416.950928
Epoch 5 / 15, step 260 / 393, loss = 1509.854614
Epoch 5 / 15, step 280 / 393, loss = 1388.961670
Epoch 5 / 15, step 300 / 393, loss = 1430.016113
Epoch 5 / 15, step 320 / 393, loss = 1483.364380
Epoch 5 / 15, step 340 / 393, loss = 1419.629395
Epoch 5 / 15, step 360 / 393, loss = 1470.881104
Epoch 5 / 15, step 380 / 393, loss = 1438.736572
TOTAL TIME ELAPSED: 0.0h, 0.25477967659632367min
Learning Rate: [4.9999999999999935e-05]
Epoch 6 / 15, step 20 / 393, loss = 1407.163696
Epoch 6 / 15, step 40 / 393, loss = 1358.116333
Epoch 6 / 15, step 60 / 393, loss = 1363.995117
Epoch 6 / 15, step 80 / 393, loss = 1445.983276
Epoch 6 / 15, step 100 / 393, loss = 1332.974976
Epoch 6 / 15, step 120 / 393, loss = 1350.469238
Epoch 6 / 15, step 140 / 393, loss = 1408.239990
Epoch 6 / 15, step 160 / 393, loss = 1379.145142
Epoch 6 / 15, step 180 / 393, loss = 1413.392334
Epoch 6 / 15, step 200 / 393, loss = 1404.725342
Epoch 6 / 15, step 220 / 393, loss = 1411.730591
Epoch 6 / 15, step 240 / 393, loss = 1364.122803
Epoch 6 / 15, step 260 / 393, loss = 1372.869995
Epoch 6 / 15, step 280 / 393, loss = 1281.743408
Epoch 6 / 15, step 300 / 393, loss = 1382.831177
Epoch 6 / 15, step 320 / 393, loss = 1431.978882
Epoch 6 / 15, step 340 / 393, loss = 1334.363770
Epoch 6 / 15, step 360 / 393, loss = 1285.314209
Epoch 6 / 15, step 380 / 393, loss = 1300.219238
TOTAL TIME ELAPSED: 0.0h, 0.3039223829905192min
Learning Rate: [4.9999999999999935e-05]
Epoch 7 / 15, step 20 / 393, loss = 1360.574097
Epoch 7 / 15, step 40 / 393, loss = 1364.268677
Epoch 7 / 15, step 60 / 393, loss = 1432.512451
Epoch 7 / 15, step 80 / 393, loss = 1281.297119
Epoch 7 / 15, step 100 / 393, loss = 1313.411377
Epoch 7 / 15, step 120 / 393, loss = 1326.316406
Epoch 7 / 15, step 140 / 393, loss = 1336.066528
Epoch 7 / 15, step 160 / 393, loss = 1334.955688
Epoch 7 / 15, step 180 / 393, loss = 1309.513916
Epoch 7 / 15, step 200 / 393, loss = 1277.124878
Epoch 7 / 15, step 220 / 393, loss = 1285.202026
Epoch 7 / 15, step 240 / 393, loss = 1301.337769
Epoch 7 / 15, step 260 / 393, loss = 1309.229248
Epoch 7 / 15, step 280 / 393, loss = 1320.053955
Epoch 7 / 15, step 300 / 393, loss = 1293.486816
Epoch 7 / 15, step 320 / 393, loss = 1283.411499
Epoch 7 / 15, step 340 / 393, loss = 1284.649780
Epoch 7 / 15, step 360 / 393, loss = 1273.537231
Epoch 7 / 15, step 380 / 393, loss = 1201.119141
TOTAL TIME ELAPSED: 0.0h, 0.3562985142072042min
Learning Rate: [4.9999999999999935e-05]
Epoch 8 / 15, step 20 / 393, loss = 1233.458008
Epoch 8 / 15, step 40 / 393, loss = 1338.762817
Epoch 8 / 15, step 60 / 393, loss = 1362.606689
Epoch 8 / 15, step 80 / 393, loss = 1234.248291
Epoch 8 / 15, step 100 / 393, loss = 1362.778687
Epoch 8 / 15, step 120 / 393, loss = 1307.912354
Epoch 8 / 15, step 140 / 393, loss = 1319.724609
Epoch 8 / 15, step 160 / 393, loss = 1232.128174
Epoch 8 / 15, step 180 / 393, loss = 1329.900513
Epoch 8 / 15, step 200 / 393, loss = 1292.088745
Epoch 8 / 15, step 220 / 393, loss = 1257.534546
Epoch 8 / 15, step 240 / 393, loss = 1270.621948
Epoch 8 / 15, step 260 / 393, loss = 1250.926025
Epoch 8 / 15, step 280 / 393, loss = 1186.049438
Epoch 8 / 15, step 300 / 393, loss = 1274.816284
Epoch 8 / 15, step 320 / 393, loss = 1228.009766
Epoch 8 / 15, step 340 / 393, loss = 1255.018921
Epoch 8 / 15, step 360 / 393, loss = 1252.626221
Epoch 8 / 15, step 380 / 393, loss = 1276.199219
TOTAL TIME ELAPSED: 0.0h, 0.4079775810241699min
Learning Rate: [4.9999999999999935e-05]
Epoch 9 / 15, step 20 / 393, loss = 1199.833008
Epoch 9 / 15, step 40 / 393, loss = 1312.739014
Epoch 9 / 15, step 60 / 393, loss = 1240.480835
Epoch 9 / 15, step 80 / 393, loss = 1169.680298
Epoch 9 / 15, step 100 / 393, loss = 1281.599365
Epoch 9 / 15, step 120 / 393, loss = 1233.397827
Epoch 9 / 15, step 140 / 393, loss = 1234.133911
Epoch 9 / 15, step 160 / 393, loss = 1240.954346
Epoch 9 / 15, step 180 / 393, loss = 1245.525757
Epoch 9 / 15, step 200 / 393, loss = 1247.531006
Epoch 9 / 15, step 220 / 393, loss = 1306.095581
Epoch 9 / 15, step 240 / 393, loss = 1274.652832
Epoch 9 / 15, step 260 / 393, loss = 1198.487549
Epoch 9 / 15, step 280 / 393, loss = 1213.649414
Epoch 9 / 15, step 300 / 393, loss = 1240.234253
Epoch 9 / 15, step 320 / 393, loss = 1230.978271
Epoch 9 / 15, step 340 / 393, loss = 1246.426514
Epoch 9 / 15, step 360 / 393, loss = 1272.157349
Epoch 9 / 15, step 380 / 393, loss = 1267.156250
TOTAL TIME ELAPSED: 0.0h, 0.4598879734675089min
Learning Rate: [4.9999999999999935e-05]
Epoch 10 / 15, step 20 / 393, loss = 1190.283447
Epoch 10 / 15, step 40 / 393, loss = 1192.005249
Epoch 10 / 15, step 60 / 393, loss = 1265.477783
Epoch 10 / 15, step 80 / 393, loss = 1171.955688
Epoch 10 / 15, step 100 / 393, loss = 1208.191162
Epoch 10 / 15, step 120 / 393, loss = 1186.427124
Epoch 10 / 15, step 140 / 393, loss = 1187.075806
Epoch 10 / 15, step 160 / 393, loss = 1178.072510
Epoch 10 / 15, step 180 / 393, loss = 1256.356201
Epoch 10 / 15, step 200 / 393, loss = 1192.229614
Epoch 10 / 15, step 220 / 393, loss = 1163.663696
Epoch 10 / 15, step 240 / 393, loss = 1206.362305
Epoch 10 / 15, step 260 / 393, loss = 1148.476807
Epoch 10 / 15, step 280 / 393, loss = 1264.814087
Epoch 10 / 15, step 300 / 393, loss = 1217.620605
Epoch 10 / 15, step 320 / 393, loss = 1185.488892
Epoch 10 / 15, step 340 / 393, loss = 1194.461548
Epoch 10 / 15, step 360 / 393, loss = 1135.058838
Epoch 10 / 15, step 380 / 393, loss = 1182.981812
TOTAL TIME ELAPSED: 0.0h, 0.510736612478892min
Learning Rate: [4.9999999999999935e-05]
Epoch 11 / 15, step 20 / 393, loss = 1169.461914
Epoch 11 / 15, step 40 / 393, loss = 1236.283569
Epoch 11 / 15, step 60 / 393, loss = 1169.809814
Epoch 11 / 15, step 80 / 393, loss = 1208.519287
Epoch 11 / 15, step 100 / 393, loss = 1207.850342
Epoch 11 / 15, step 120 / 393, loss = 1171.577148
Epoch 11 / 15, step 140 / 393, loss = 1160.499634
Epoch 11 / 15, step 160 / 393, loss = 1204.073364
Epoch 11 / 15, step 180 / 393, loss = 1225.387207
Epoch 11 / 15, step 200 / 393, loss = 1267.997925
Epoch 11 / 15, step 220 / 393, loss = 1220.956299
Epoch 11 / 15, step 240 / 393, loss = 1249.137695
Epoch 11 / 15, step 260 / 393, loss = 1123.552734
Epoch 11 / 15, step 280 / 393, loss = 1194.980469
Epoch 11 / 15, step 300 / 393, loss = 1176.883789
Epoch 11 / 15, step 320 / 393, loss = 1160.278564
Epoch 11 / 15, step 340 / 393, loss = 1124.804688
Epoch 11 / 15, step 360 / 393, loss = 1127.802856
Epoch 11 / 15, step 380 / 393, loss = 1184.663208
TOTAL TIME ELAPSED: 0.0h, 0.5611732204755148min
Learning Rate: [4.9999999999999935e-05]
Epoch 12 / 15, step 20 / 393, loss = 1197.056885
Epoch 12 / 15, step 40 / 393, loss = 1165.925781
Epoch 12 / 15, step 60 / 393, loss = 1218.008789
Epoch 12 / 15, step 80 / 393, loss = 1189.276123
Epoch 12 / 15, step 100 / 393, loss = 1149.857788
Epoch 12 / 15, step 120 / 393, loss = 1226.515991
Epoch 12 / 15, step 140 / 393, loss = 1265.438599
Epoch 12 / 15, step 160 / 393, loss = 1170.446655
Epoch 12 / 15, step 180 / 393, loss = 1152.758057
Epoch 12 / 15, step 200 / 393, loss = 1180.790283
Epoch 12 / 15, step 220 / 393, loss = 1228.053711
Epoch 12 / 15, step 240 / 393, loss = 1157.173950
Epoch 12 / 15, step 260 / 393, loss = 1198.985229
Epoch 12 / 15, step 280 / 393, loss = 1219.662598
Epoch 12 / 15, step 300 / 393, loss = 1210.393677
Epoch 12 / 15, step 320 / 393, loss = 1196.667847
Epoch 12 / 15, step 340 / 393, loss = 1163.238281
Epoch 12 / 15, step 360 / 393, loss = 1136.159180
Epoch 12 / 15, step 380 / 393, loss = 1210.356445
TOTAL TIME ELAPSED: 0.0h, 0.6124992926915487min
Learning Rate: [4.9999999999999935e-05]
Epoch 13 / 15, step 20 / 393, loss = 1149.763672
Epoch 13 / 15, step 40 / 393, loss = 1123.753784
Epoch 13 / 15, step 60 / 393, loss = 1129.711304
Epoch 13 / 15, step 80 / 393, loss = 1143.626343
Epoch 13 / 15, step 100 / 393, loss = 1146.193848
Epoch 13 / 15, step 120 / 393, loss = 1141.719360
Epoch 13 / 15, step 140 / 393, loss = 1210.373779
Epoch 13 / 15, step 160 / 393, loss = 1125.897583
Epoch 13 / 15, step 180 / 393, loss = 1111.684692
Epoch 13 / 15, step 200 / 393, loss = 1177.284668
Epoch 13 / 15, step 220 / 393, loss = 1237.773071
Epoch 13 / 15, step 240 / 393, loss = 1163.813354
Epoch 13 / 15, step 260 / 393, loss = 1139.816040
Epoch 13 / 15, step 280 / 393, loss = 1179.114624
Epoch 13 / 15, step 300 / 393, loss = 1202.837524
Epoch 13 / 15, step 320 / 393, loss = 1160.849121
Epoch 13 / 15, step 340 / 393, loss = 1122.319458
Epoch 13 / 15, step 360 / 393, loss = 1115.283813
Epoch 13 / 15, step 380 / 393, loss = 1144.793701
TOTAL TIME ELAPSED: 0.0h, 0.6622233549753825min
Learning Rate: [4.9999999999999935e-05]
Epoch 14 / 15, step 20 / 393, loss = 1125.491455
Epoch 14 / 15, step 40 / 393, loss = 1056.337036
Epoch 14 / 15, step 60 / 393, loss = 1202.924438
Epoch 14 / 15, step 80 / 393, loss = 1324.907227
Epoch 14 / 15, step 100 / 393, loss = 1165.153320
Epoch 14 / 15, step 120 / 393, loss = 1179.145020
Epoch 14 / 15, step 140 / 393, loss = 1202.358154
Epoch 14 / 15, step 160 / 393, loss = 1133.585327
Epoch 14 / 15, step 180 / 393, loss = 1167.596802
Epoch 14 / 15, step 200 / 393, loss = 1163.286499
Epoch 14 / 15, step 220 / 393, loss = 1149.831665
Epoch 14 / 15, step 240 / 393, loss = 1168.729492
Epoch 14 / 15, step 260 / 393, loss = 1142.670776
Epoch 14 / 15, step 280 / 393, loss = 1172.607910
Epoch 14 / 15, step 300 / 393, loss = 1072.746460
Epoch 14 / 15, step 320 / 393, loss = 1101.815308
Epoch 14 / 15, step 340 / 393, loss = 1156.045044
Epoch 14 / 15, step 360 / 393, loss = 1194.795166
Epoch 14 / 15, step 380 / 393, loss = 1230.045654
TOTAL TIME ELAPSED: 0.0h, 0.7145553668340047min
Learning Rate: [4.9999999999999935e-05]
Epoch 15 / 15, step 20 / 393, loss = 1161.034790
Epoch 15 / 15, step 40 / 393, loss = 1149.104736
Epoch 15 / 15, step 60 / 393, loss = 1245.069458
Epoch 15 / 15, step 80 / 393, loss = 1179.290649
Epoch 15 / 15, step 100 / 393, loss = 1144.983521
Epoch 15 / 15, step 120 / 393, loss = 1109.042114
Epoch 15 / 15, step 140 / 393, loss = 1117.544312
Epoch 15 / 15, step 160 / 393, loss = 1114.293945
Epoch 15 / 15, step 180 / 393, loss = 1158.844971
Epoch 15 / 15, step 200 / 393, loss = 1122.936401
Epoch 15 / 15, step 220 / 393, loss = 1190.564575
Epoch 15 / 15, step 240 / 393, loss = 1153.150879
Epoch 15 / 15, step 260 / 393, loss = 1152.332520
/home/joao/miniconda3/envs/da/lib/python3.11/site-packages/torch/nn/functional.py:4316: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
Epoch 15 / 15, step 300 / 393, loss = 1169.695312
Epoch 15 / 15, step 320 / 393, loss = 1122.036987
Epoch 15 / 15, step 340 / 393, loss = 1093.123413
Epoch 15 / 15, step 360 / 393, loss = 1174.394775
Epoch 15 / 15, step 380 / 393, loss = 1180.010132
TOTAL TIME ELAPSED: 0.0h, 0.7663885712623596min
TESTING...
/home/joao/miniconda3/envs/da/lib/python3.11/site-packages/torch/nn/functional.py:4316: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
Test Accuracy: 0.2739079643585221
Majority Voting Accuracy: 0.3162393162393162
FINE-TUNING...
Learning Rate: [5e-05]
Epoch 1 / 150, step 20 / 35, loss = 2919.416748
TOTAL TIME ELAPSED: 0.0h, 0.004132552941640218min
Learning Rate: [5.450000000000003e-06]
Epoch 2 / 150, step 20 / 35, loss = 2949.014893
TOTAL TIME ELAPSED: 0.0h, 0.007949761549631755min
Learning Rate: [1.0400000000000007e-05]
Epoch 3 / 150, step 20 / 35, loss = 3002.593750
TOTAL TIME ELAPSED: 0.0h, 0.013810837268829345min
Learning Rate: [1.5349999999999997e-05]
Epoch 4 / 150, step 20 / 35, loss = 2943.365479
TOTAL TIME ELAPSED: 0.0h, 0.017738544940948488min
Learning Rate: [2.029999999999999e-05]
Epoch 5 / 150, step 20 / 35, loss = 2903.030273
TOTAL TIME ELAPSED: 0.0h, 0.02165233294169108min
Learning Rate: [2.5249999999999994e-05]
Epoch 6 / 150, step 20 / 35, loss = 3074.115967
TOTAL TIME ELAPSED: 0.0h, 0.02548983891805013min
Learning Rate: [3.020000000000001e-05]
Epoch 7 / 150, step 20 / 35, loss = 2878.489014
TOTAL TIME ELAPSED: 0.0h, 0.030979637304941812min
Learning Rate: [3.515000000000003e-05]
Epoch 8 / 150, step 20 / 35, loss = 3047.318115
TOTAL TIME ELAPSED: 0.0h, 0.034737058480580646min
Learning Rate: [4.0100000000000006e-05]
Epoch 9 / 150, step 20 / 35, loss = 2972.854248
TOTAL TIME ELAPSED: 0.0h, 0.038526856899261476min
Learning Rate: [4.5049999999999984e-05]
Epoch 10 / 150, step 20 / 35, loss = 2893.567139
TOTAL TIME ELAPSED: 0.0h, 0.0439759095509847min
Learning Rate: [4.9999999999999996e-05]
Epoch 11 / 150, step 20 / 35, loss = 3006.664062
TOTAL TIME ELAPSED: 0.0h, 0.04776758750279744min
Learning Rate: [4.9999999999999996e-05]
Epoch 12 / 150, step 20 / 35, loss = 3009.353271
TOTAL TIME ELAPSED: 0.0h, 0.053465179602305096min
Learning Rate: [4.9999999999999996e-05]
Epoch 13 / 150, step 20 / 35, loss = 2916.569580
TOTAL TIME ELAPSED: 0.0h, 0.05731065273284912min
Learning Rate: [4.9999999999999996e-05]
Epoch 14 / 150, step 20 / 35, loss = 2849.629883
TOTAL TIME ELAPSED: 0.0h, 0.061176733175913496min
Learning Rate: [4.9999999999999996e-05]
Epoch 15 / 150, step 20 / 35, loss = 2898.687012
TOTAL TIME ELAPSED: 0.0h, 0.06671404441197713min
Learning Rate: [4.9999999999999996e-05]
Epoch 16 / 150, step 20 / 35, loss = 2893.921631
TOTAL TIME ELAPSED: 0.0h, 0.07053163846333822min
Learning Rate: [4.9999999999999996e-05]
Epoch 17 / 150, step 20 / 35, loss = 2896.951172
TOTAL TIME ELAPSED: 0.0h, 0.07420600652694702min
Learning Rate: [4.9999999999999996e-05]
Epoch 18 / 150, step 20 / 35, loss = 2843.193115
TOTAL TIME ELAPSED: 0.0h, 0.07966574827829996min
Learning Rate: [4.9999999999999996e-05]
Epoch 19 / 150, step 20 / 35, loss = 2914.755371
TOTAL TIME ELAPSED: 0.0h, 0.08364061117172242min
Learning Rate: [4.9999999999999996e-05]
Epoch 20 / 150, step 20 / 35, loss = 2933.890869
TOTAL TIME ELAPSED: 0.0h, 0.08738224903742473min
Learning Rate: [4.9999999999999996e-05]
Epoch 21 / 150, step 20 / 35, loss = 3031.797363
TOTAL TIME ELAPSED: 0.0h, 0.09278116623560588min
Learning Rate: [4.9999999999999996e-05]
Epoch 22 / 150, step 20 / 35, loss = 2923.253174
TOTAL TIME ELAPSED: 0.0h, 0.09668234984079997min
Learning Rate: [4.9999999999999996e-05]
Epoch 23 / 150, step 20 / 35, loss = 2961.103271
TOTAL TIME ELAPSED: 0.0h, 0.10227665106455484min
Learning Rate: [4.9999999999999996e-05]
Epoch 24 / 150, step 20 / 35, loss = 2900.944092
TOTAL TIME ELAPSED: 0.0h, 0.10605715115865072min
Learning Rate: [4.9999999999999996e-05]
Epoch 25 / 150, step 20 / 35, loss = 3021.305420
TOTAL TIME ELAPSED: 0.0h, 0.10977719227472942min
Learning Rate: [4.9999999999999996e-05]
Epoch 26 / 150, step 20 / 35, loss = 3007.501953
TOTAL TIME ELAPSED: 0.0h, 0.11515659888585408min
Learning Rate: [4.9999999999999996e-05]
Epoch 27 / 150, step 20 / 35, loss = 3082.979492
TOTAL TIME ELAPSED: 0.0h, 0.11882514158884684min
Learning Rate: [4.9999999999999996e-05]
Epoch 28 / 150, step 20 / 35, loss = 2982.496338
TOTAL TIME ELAPSED: 0.0h, 0.12247679630915324min
Learning Rate: [4.9999999999999996e-05]
Epoch 29 / 150, step 20 / 35, loss = 3013.043701
TOTAL TIME ELAPSED: 0.0h, 0.12792162497838339min
Learning Rate: [4.9999999999999996e-05]
Epoch 30 / 150, step 20 / 35, loss = 2934.176270
TOTAL TIME ELAPSED: 0.0h, 0.13156913916269938min
Learning Rate: [4.9999999999999996e-05]
Epoch 31 / 150, step 20 / 35, loss = 2860.422607
TOTAL TIME ELAPSED: 0.0h, 0.13524096806844074min
Learning Rate: [4.9999999999999996e-05]
Epoch 32 / 150, step 20 / 35, loss = 3076.399902
TOTAL TIME ELAPSED: 0.0h, 0.14066349267959594min
Learning Rate: [4.9999999999999996e-05]
Epoch 33 / 150, step 20 / 35, loss = 2927.882080
TOTAL TIME ELAPSED: 0.0h, 0.14437458117802937min
Learning Rate: [4.9999999999999996e-05]
Epoch 34 / 150, step 20 / 35, loss = 2883.111816
TOTAL TIME ELAPSED: 0.0h, 0.14807331164677937min
Learning Rate: [4.9999999999999996e-05]
Epoch 35 / 150, step 20 / 35, loss = 3060.758545
TOTAL TIME ELAPSED: 0.0h, 0.1534988284111023min
Learning Rate: [4.9999999999999996e-05]
Epoch 36 / 150, step 20 / 35, loss = 2868.184814
TOTAL TIME ELAPSED: 0.0h, 0.15712857643763226min
Learning Rate: [4.9999999999999996e-05]
Epoch 37 / 150, step 20 / 35, loss = 2987.196045
TOTAL TIME ELAPSED: 0.0h, 0.16084741353988646min
Learning Rate: [4.9999999999999996e-05]
Epoch 38 / 150, step 20 / 35, loss = 3000.086426
TOTAL TIME ELAPSED: 0.0h, 0.16618995666503905min
Learning Rate: [4.9999999999999996e-05]
Epoch 39 / 150, step 20 / 35, loss = 2915.177734
TOTAL TIME ELAPSED: 0.0h, 0.1699339985847473min
Learning Rate: [4.9999999999999996e-05]
Epoch 40 / 150, step 20 / 35, loss = 2912.224365
TOTAL TIME ELAPSED: 0.0h, 0.17531009117762247min
Learning Rate: [4.9999999999999996e-05]
Epoch 41 / 150, step 20 / 35, loss = 3099.133301
TOTAL TIME ELAPSED: 0.0h, 0.1790324886639913min
Learning Rate: [4.9999999999999996e-05]
Epoch 42 / 150, step 20 / 35, loss = 3039.338379
TOTAL TIME ELAPSED: 0.0h, 0.1828830361366272min
Learning Rate: [4.9999999999999996e-05]
Epoch 43 / 150, step 20 / 35, loss = 3087.291748
TOTAL TIME ELAPSED: 0.0h, 0.18842109839121501min
Learning Rate: [4.9999999999999996e-05]
Epoch 44 / 150, step 20 / 35, loss = 2910.374512
TOTAL TIME ELAPSED: 0.0h, 0.19224162499109904min
Learning Rate: [4.9999999999999996e-05]
Epoch 45 / 150, step 20 / 35, loss = 3062.493896
TOTAL TIME ELAPSED: 0.0h, 0.19597886403401693min
Learning Rate: [4.9999999999999996e-05]
Epoch 46 / 150, step 20 / 35, loss = 2981.989014
TOTAL TIME ELAPSED: 0.0h, 0.20158166885375978min
Learning Rate: [4.9999999999999996e-05]
Epoch 47 / 150, step 20 / 35, loss = 2993.183350
TOTAL TIME ELAPSED: 0.0h, 0.20526285966237387min
Learning Rate: [4.9999999999999996e-05]
Epoch 48 / 150, step 20 / 35, loss = 3009.299561
TOTAL TIME ELAPSED: 0.0h, 0.2089560588200887min
Learning Rate: [4.9999999999999996e-05]
Epoch 49 / 150, step 20 / 35, loss = 3183.205566
TOTAL TIME ELAPSED: 0.0h, 0.2143729368845622min
Learning Rate: [4.9999999999999996e-05]
Epoch 50 / 150, step 20 / 35, loss = 3109.772461
TOTAL TIME ELAPSED: 0.0h, 0.21809625228246052min
Learning Rate: [4.9999999999999996e-05]
Epoch 51 / 150, step 20 / 35, loss = 2942.637939
TOTAL TIME ELAPSED: 0.0h, 0.22182968060175579min
Learning Rate: [4.9999999999999996e-05]
Epoch 52 / 150, step 20 / 35, loss = 3133.844238
TOTAL TIME ELAPSED: 0.0h, 0.2272307236989339min
Learning Rate: [4.9999999999999996e-05]
Epoch 53 / 150, step 20 / 35, loss = 2964.861572
TOTAL TIME ELAPSED: 0.0h, 0.23095914125442504min
Learning Rate: [4.9999999999999996e-05]
Epoch 54 / 150, step 20 / 35, loss = 2753.578125
TOTAL TIME ELAPSED: 0.0h, 0.23470731178919474min
Learning Rate: [4.9999999999999996e-05]
Epoch 55 / 150, step 20 / 35, loss = 2960.981934
TOTAL TIME ELAPSED: 0.0h, 0.24016529321670532min
Learning Rate: [4.9999999999999996e-05]
Epoch 56 / 150, step 20 / 35, loss = 3000.946289
TOTAL TIME ELAPSED: 0.0h, 0.24413733084996542min
Learning Rate: [4.9999999999999996e-05]
Epoch 57 / 150, step 20 / 35, loss = 2994.467529
TOTAL TIME ELAPSED: 0.0h, 0.24973655541737874min
Learning Rate: [4.9999999999999996e-05]
Epoch 58 / 150, step 20 / 35, loss = 2987.154053
TOTAL TIME ELAPSED: 0.0h, 0.25349974632263184min
Learning Rate: [4.9999999999999996e-05]
Epoch 59 / 150, step 20 / 35, loss = 3004.162842
TOTAL TIME ELAPSED: 0.0h, 0.25731188456217446min
Learning Rate: [4.9999999999999996e-05]
Epoch 60 / 150, step 20 / 35, loss = 2904.042969
TOTAL TIME ELAPSED: 0.0h, 0.263027282555898min
Learning Rate: [4.9999999999999996e-05]
Epoch 61 / 150, step 20 / 35, loss = 3008.555176
TOTAL TIME ELAPSED: 0.0h, 0.2671131451924642min
Learning Rate: [4.9999999999999996e-05]
Epoch 62 / 150, step 20 / 35, loss = 2875.515869
TOTAL TIME ELAPSED: 0.0h, 0.27094960610071817min
Learning Rate: [4.9999999999999996e-05]
Epoch 63 / 150, step 20 / 35, loss = 2952.625488
TOTAL TIME ELAPSED: 0.0h, 0.27656548023223876min
Learning Rate: [4.9999999999999996e-05]
Epoch 64 / 150, step 20 / 35, loss = 3049.470947
TOTAL TIME ELAPSED: 0.0h, 0.28033862511316937min
Learning Rate: [4.9999999999999996e-05]
Epoch 65 / 150, step 20 / 35, loss = 2994.401855
TOTAL TIME ELAPSED: 0.0h, 0.28408440748850505min
Learning Rate: [4.9999999999999996e-05]
Epoch 66 / 150, step 20 / 35, loss = 3106.364502
TOTAL TIME ELAPSED: 0.0h, 0.2895948966344198min
Learning Rate: [4.9999999999999996e-05]
Epoch 67 / 150, step 20 / 35, loss = 3141.693604
TOTAL TIME ELAPSED: 0.0h, 0.2933564782142639min
Learning Rate: [4.9999999999999996e-05]
Epoch 68 / 150, step 20 / 35, loss = 2894.488770
TOTAL TIME ELAPSED: 0.0h, 0.2971583525339762min
Learning Rate: [4.9999999999999996e-05]
Epoch 69 / 150, step 20 / 35, loss = 2982.378906
TOTAL TIME ELAPSED: 0.0h, 0.30267626444498696min
Learning Rate: [4.9999999999999996e-05]
Epoch 70 / 150, step 20 / 35, loss = 3025.624512
TOTAL TIME ELAPSED: 0.0h, 0.30642381906509397min
Learning Rate: [4.9999999999999996e-05]
Epoch 71 / 150, step 20 / 35, loss = 2881.461426
TOTAL TIME ELAPSED: 0.0h, 0.31021583477656045min
Learning Rate: [4.9999999999999996e-05]
Epoch 72 / 150, step 20 / 35, loss = 3087.803223
TOTAL TIME ELAPSED: 0.0h, 0.31565330028533933min
Learning Rate: [4.9999999999999996e-05]
Epoch 73 / 150, step 20 / 35, loss = 2860.467773
TOTAL TIME ELAPSED: 0.0h, 0.3193237980206807min
Learning Rate: [4.9999999999999996e-05]
Epoch 74 / 150, step 20 / 35, loss = 3024.690918
TOTAL TIME ELAPSED: 0.0h, 0.32477855682373047min
Learning Rate: [4.9999999999999996e-05]
Epoch 75 / 150, step 20 / 35, loss = 2980.595215
TOTAL TIME ELAPSED: 0.0h, 0.3286634961764018min
Learning Rate: [4.9999999999999996e-05]
Epoch 76 / 150, step 20 / 35, loss = 2927.098145
TOTAL TIME ELAPSED: 0.0h, 0.33234241406122844min
Learning Rate: [4.9999999999999996e-05]
Epoch 77 / 150, step 20 / 35, loss = 2976.729492
TOTAL TIME ELAPSED: 0.0h, 0.337808883190155min
Learning Rate: [4.9999999999999996e-05]
Epoch 78 / 150, step 20 / 35, loss = 2824.648682
TOTAL TIME ELAPSED: 0.0h, 0.34151494105656943min
Learning Rate: [4.9999999999999996e-05]
Epoch 79 / 150, step 20 / 35, loss = 3069.941895
TOTAL TIME ELAPSED: 0.0h, 0.34526079098383583min
Learning Rate: [4.9999999999999996e-05]
Epoch 80 / 150, step 20 / 35, loss = 3050.515381
TOTAL TIME ELAPSED: 0.0h, 0.3508139491081238min
Learning Rate: [4.9999999999999996e-05]
Epoch 81 / 150, step 20 / 35, loss = 2962.063232
TOTAL TIME ELAPSED: 0.0h, 0.3544870535532633min
Learning Rate: [4.9999999999999996e-05]
Epoch 82 / 150, step 20 / 35, loss = 2883.439453
TOTAL TIME ELAPSED: 0.0h, 0.358144736289978min
Learning Rate: [4.9999999999999996e-05]
Epoch 83 / 150, step 20 / 35, loss = 2985.452637
TOTAL TIME ELAPSED: 0.0h, 0.3635440389315287min
Learning Rate: [4.9999999999999996e-05]
Epoch 84 / 150, step 20 / 35, loss = 2945.931885
TOTAL TIME ELAPSED: 0.0h, 0.36726247469584145min
Learning Rate: [4.9999999999999996e-05]
Epoch 85 / 150, step 20 / 35, loss = 2998.640625
TOTAL TIME ELAPSED: 0.0h, 0.3709519108136495min
Learning Rate: [4.9999999999999996e-05]
Epoch 86 / 150, step 20 / 35, loss = 3053.306641
TOTAL TIME ELAPSED: 0.0h, 0.3763993620872498min
Learning Rate: [4.9999999999999996e-05]
Epoch 87 / 150, step 20 / 35, loss = 2884.225586
TOTAL TIME ELAPSED: 0.0h, 0.38012668689092min
Learning Rate: [4.9999999999999996e-05]
Epoch 88 / 150, step 20 / 35, loss = 3039.512695
TOTAL TIME ELAPSED: 0.0h, 0.38553078174591066min
Learning Rate: [4.9999999999999996e-05]
Epoch 89 / 150, step 20 / 35, loss = 3050.771240
TOTAL TIME ELAPSED: 0.0h, 0.3891398509343465min
Learning Rate: [4.9999999999999996e-05]
Epoch 90 / 150, step 20 / 35, loss = 3101.497559
TOTAL TIME ELAPSED: 0.0h, 0.3927166263262431min
Learning Rate: [4.9999999999999996e-05]
Epoch 91 / 150, step 20 / 35, loss = 2920.744385
TOTAL TIME ELAPSED: 0.0h, 0.39636592864990233min
Learning Rate: [4.9999999999999996e-05]
Epoch 92 / 150, step 20 / 35, loss = 2813.278809
TOTAL TIME ELAPSED: 0.0h, 0.40004772345225015min
Learning Rate: [4.9999999999999996e-05]
Epoch 93 / 150, step 20 / 35, loss = 2910.302979
TOTAL TIME ELAPSED: 0.0h, 0.40371708075205487min
Learning Rate: [4.9999999999999996e-05]
Epoch 94 / 150, step 20 / 35, loss = 2945.414062
TOTAL TIME ELAPSED: 0.0h, 0.40735950469970705min
Learning Rate: [4.9999999999999996e-05]
Epoch 95 / 150, step 20 / 35, loss = 2946.041992
TOTAL TIME ELAPSED: 0.0h, 0.41105717023213706min
Learning Rate: [4.9999999999999996e-05]
Epoch 96 / 150, step 20 / 35, loss = 3057.798828
TOTAL TIME ELAPSED: 0.0h, 0.4146997650464376min
Learning Rate: [4.9999999999999996e-05]
Epoch 97 / 150, step 20 / 35, loss = 2904.603271
TOTAL TIME ELAPSED: 0.0h, 0.41866477727890017min
Learning Rate: [4.9999999999999996e-05]
Epoch 98 / 150, step 20 / 35, loss = 3124.718750
TOTAL TIME ELAPSED: 0.0h, 0.42239787181218463min
Learning Rate: [4.9999999999999996e-05]
Epoch 99 / 150, step 20 / 35, loss = 3067.478516
TOTAL TIME ELAPSED: 0.0h, 0.4278907855351766min
Learning Rate: [4.9999999999999996e-05]
Epoch 100 / 150, step 20 / 35, loss = 2951.537354
TOTAL TIME ELAPSED: 0.0h, 0.4317365606625875min
Learning Rate: [4.9999999999999996e-05]
Epoch 101 / 150, step 20 / 35, loss = 2942.650635
TOTAL TIME ELAPSED: 0.0h, 0.4355331778526306min
Learning Rate: [4.9999999999999996e-05]
Epoch 102 / 150, step 20 / 35, loss = 2797.974121
TOTAL TIME ELAPSED: 0.0h, 0.4393325448036194min
Learning Rate: [4.9999999999999996e-05]
Epoch 103 / 150, step 20 / 35, loss = 3121.646240
TOTAL TIME ELAPSED: 0.0h, 0.4431285262107849min
Learning Rate: [4.9999999999999996e-05]
Epoch 104 / 150, step 20 / 35, loss = 2975.374512
TOTAL TIME ELAPSED: 0.0h, 0.44871225357055666min
Learning Rate: [4.9999999999999996e-05]
Epoch 105 / 150, step 20 / 35, loss = 2901.506592
TOTAL TIME ELAPSED: 0.0h, 0.45248568852742516min
Learning Rate: [4.9999999999999996e-05]
Epoch 106 / 150, step 20 / 35, loss = 3077.083496
TOTAL TIME ELAPSED: 0.0h, 0.4562988758087158min
Learning Rate: [4.9999999999999996e-05]
Epoch 107 / 150, step 20 / 35, loss = 2917.273438
TOTAL TIME ELAPSED: 0.0h, 0.46200904448827107min
Learning Rate: [4.9999999999999996e-05]
Epoch 108 / 150, step 20 / 35, loss = 2894.552002
TOTAL TIME ELAPSED: 0.0h, 0.46577725013097127min
Learning Rate: [4.9999999999999996e-05]
Epoch 109 / 150, step 20 / 35, loss = 2869.213623
TOTAL TIME ELAPSED: 0.0h, 0.4695940415064494min
Learning Rate: [4.9999999999999996e-05]
Epoch 110 / 150, step 20 / 35, loss = 3013.289795
TOTAL TIME ELAPSED: 0.0h, 0.4751763661702474min
Learning Rate: [4.9999999999999996e-05]
Epoch 111 / 150, step 20 / 35, loss = 2889.133057
TOTAL TIME ELAPSED: 0.0h, 0.4789819876352946min
Learning Rate: [4.9999999999999996e-05]
Epoch 112 / 150, step 20 / 35, loss = 2809.013672
TOTAL TIME ELAPSED: 0.0h, 0.4827199657758077min
Learning Rate: [4.9999999999999996e-05]
Epoch 113 / 150, step 20 / 35, loss = 3089.839600
TOTAL TIME ELAPSED: 0.0h, 0.48834025859832764min
Learning Rate: [4.9999999999999996e-05]
Epoch 114 / 150, step 20 / 35, loss = 2885.898193
TOTAL TIME ELAPSED: 0.0h, 0.4921138048171997min
Learning Rate: [4.9999999999999996e-05]
Epoch 115 / 150, step 20 / 35, loss = 3086.588379
TOTAL TIME ELAPSED: 0.0h, 0.49588606754938763min
Learning Rate: [4.9999999999999996e-05]
Epoch 116 / 150, step 20 / 35, loss = 3102.022949
TOTAL TIME ELAPSED: 0.0h, 0.5014550646146139min
Learning Rate: [4.9999999999999996e-05]
Epoch 117 / 150, step 20 / 35, loss = 3068.883301
TOTAL TIME ELAPSED: 0.0h, 0.5054004033406575min
Learning Rate: [4.9999999999999996e-05]
Epoch 118 / 150, step 20 / 35, loss = 3002.243408
TOTAL TIME ELAPSED: 0.0h, 0.5092199563980102min
Learning Rate: [4.9999999999999996e-05]
Epoch 119 / 150, step 20 / 35, loss = 2917.379150
TOTAL TIME ELAPSED: 0.0h, 0.5148450056711833min
Learning Rate: [4.9999999999999996e-05]
Epoch 120 / 150, step 20 / 35, loss = 3049.616211
TOTAL TIME ELAPSED: 0.0h, 0.5187112887700399min
Learning Rate: [4.9999999999999996e-05]
Epoch 121 / 150, step 20 / 35, loss = 2894.652832
TOTAL TIME ELAPSED: 0.0h, 0.5243735273679098min
Learning Rate: [4.9999999999999996e-05]
Epoch 122 / 150, step 20 / 35, loss = 3061.314209
TOTAL TIME ELAPSED: 0.0h, 0.5281735102335612min
Learning Rate: [4.9999999999999996e-05]
Epoch 123 / 150, step 20 / 35, loss = 2989.711182
TOTAL TIME ELAPSED: 0.0h, 0.5319535533587137min
Learning Rate: [4.9999999999999996e-05]
Epoch 124 / 150, step 20 / 35, loss = 2872.982910
TOTAL TIME ELAPSED: 0.0h, 0.537676211198171min
Learning Rate: [4.9999999999999996e-05]
Epoch 125 / 150, step 20 / 35, loss = 2990.418457
TOTAL TIME ELAPSED: 0.0h, 0.541426412264506min
Learning Rate: [4.9999999999999996e-05]
Epoch 126 / 150, step 20 / 35, loss = 3109.452148
TOTAL TIME ELAPSED: 0.0h, 0.5452637592951457min
Learning Rate: [4.9999999999999996e-05]
Epoch 127 / 150, step 20 / 35, loss = 3072.422852
TOTAL TIME ELAPSED: 0.0h, 0.550919238726298min
Learning Rate: [4.9999999999999996e-05]
Epoch 128 / 150, step 20 / 35, loss = 2876.040283
TOTAL TIME ELAPSED: 0.0h, 0.5546982010205587min
Learning Rate: [4.9999999999999996e-05]
Epoch 129 / 150, step 20 / 35, loss = 2997.205078
TOTAL TIME ELAPSED: 0.0h, 0.5584829529126485min
Learning Rate: [4.9999999999999996e-05]
Epoch 130 / 150, step 20 / 35, loss = 3022.010498
TOTAL TIME ELAPSED: 0.0h, 0.5642342925071716min
Learning Rate: [4.9999999999999996e-05]
Epoch 131 / 150, step 20 / 35, loss = 3092.622803
TOTAL TIME ELAPSED: 0.0h, 0.5680320501327515min
Learning Rate: [4.9999999999999996e-05]
Epoch 132 / 150, step 20 / 35, loss = 2896.936279
TOTAL TIME ELAPSED: 0.0h, 0.5718682050704956min
Learning Rate: [4.9999999999999996e-05]
Epoch 133 / 150, step 20 / 35, loss = 2999.160645
TOTAL TIME ELAPSED: 0.0h, 0.5774619698524475min
Learning Rate: [4.9999999999999996e-05]
Epoch 134 / 150, step 20 / 35, loss = 2866.004395
TOTAL TIME ELAPSED: 0.0h, 0.5812076369921366min
Learning Rate: [4.9999999999999996e-05]
Epoch 135 / 150, step 20 / 35, loss = 3026.552979
TOTAL TIME ELAPSED: 0.0h, 0.5850780844688416min
Learning Rate: [4.9999999999999996e-05]
Epoch 136 / 150, step 20 / 35, loss = 2985.081543
TOTAL TIME ELAPSED: 0.0h, 0.5906582156817118min
Learning Rate: [4.9999999999999996e-05]
Epoch 137 / 150, step 20 / 35, loss = 2934.112549
TOTAL TIME ELAPSED: 0.0h, 0.5944543321927388min
Learning Rate: [4.9999999999999996e-05]
Epoch 138 / 150, step 20 / 35, loss = 2979.356934
TOTAL TIME ELAPSED: 0.0h, 0.6001916329065958min
Learning Rate: [4.9999999999999996e-05]
Epoch 139 / 150, step 20 / 35, loss = 3141.378906
TOTAL TIME ELAPSED: 0.0h, 0.6040184299151102min
Learning Rate: [4.9999999999999996e-05]
Epoch 140 / 150, step 20 / 35, loss = 2995.237061
TOTAL TIME ELAPSED: 0.0h, 0.6078218817710876min
Learning Rate: [4.9999999999999996e-05]
Epoch 141 / 150, step 20 / 35, loss = 2990.609375
TOTAL TIME ELAPSED: 0.0h, 0.613571806748708min
Learning Rate: [4.9999999999999996e-05]
Epoch 142 / 150, step 20 / 35, loss = 3027.250000
TOTAL TIME ELAPSED: 0.0h, 0.6174375693003337min
Learning Rate: [4.9999999999999996e-05]
Epoch 143 / 150, step 20 / 35, loss = 2722.008301
TOTAL TIME ELAPSED: 0.0h, 0.6212967356046041min
Learning Rate: [4.9999999999999996e-05]
Epoch 144 / 150, step 20 / 35, loss = 2856.193604
TOTAL TIME ELAPSED: 0.0h, 0.6270177006721497min
Learning Rate: [4.9999999999999996e-05]
Epoch 145 / 150, step 20 / 35, loss = 2934.242676
TOTAL TIME ELAPSED: 0.0h, 0.6308840115865072min
Learning Rate: [4.9999999999999996e-05]
Epoch 146 / 150, step 20 / 35, loss = 3108.629639
TOTAL TIME ELAPSED: 0.0h, 0.6346298972765605min
Learning Rate: [4.9999999999999996e-05]
Epoch 147 / 150, step 20 / 35, loss = 2929.780762
TOTAL TIME ELAPSED: 0.0h, 0.640355130036672min
Learning Rate: [4.9999999999999996e-05]
Epoch 148 / 150, step 20 / 35, loss = 3077.292236
TOTAL TIME ELAPSED: 0.0h, 0.6441507339477539min
Learning Rate: [4.9999999999999996e-05]
Epoch 149 / 150, step 20 / 35, loss = 2885.688477
TOTAL TIME ELAPSED: 0.0h, 0.6479683518409729min
Learning Rate: [4.9999999999999996e-05]
/home/joao/miniconda3/envs/da/lib/python3.11/site-packages/torch/nn/functional.py:4316: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
Epoch 150 / 150, step 20 / 35, loss = 2961.579346
TOTAL TIME ELAPSED: 0.0h, 0.6535321990648906min
TESTING...
LEARNED SHIFTS: x: 0.0 , y: 0.0
 50%|███████████████████████████████████████▌                                       | 1/2 [01:48<01:48, 108.98s/it]
  0%|                                                                                        | 0/2 [01:48<?, ?it/s]
0it [02:31, ?it/s]
Tuned Test Accuracy: 0.2739079643585221
Majority Voting Tuned Accuracy: 0.3162393162393162
